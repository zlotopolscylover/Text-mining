{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warsztaty badawcze 2\n",
    "## Projekt\n",
    "### Andżelika Zalewska\n",
    "12.05.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cel projektu: Zbudowanie modelu predykcyjnego z wykorzystaniem poznanych technik text miningu w oparciu o zbiór treningowy złożony z 7 zmiennych objaśniających. Zbiór zawiera 10268 obserwacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation\n",
    "import spacy\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         label                                          statement  \\\n",
      "0    half-true  When did the decline of coal start? It started...   \n",
      "1  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
      "2        false  Health care reform legislation is likely to ma...   \n",
      "3    half-true  The economic turnaround started at the end of ...   \n",
      "4         true  The Chicago Bears have had more starting quart...   \n",
      "\n",
      "                              subject         speaker  \\\n",
      "0  energy,history,job-accomplishments  scott-surovell   \n",
      "1                      foreign-policy    barack-obama   \n",
      "2                         health-care    blog-posting   \n",
      "3                        economy,jobs   charlie-crist   \n",
      "4                           education       robin-vos   \n",
      "\n",
      "                  speaker_job      state       party  \\\n",
      "0              State delegate   Virginia    democrat   \n",
      "1                   President   Illinois    democrat   \n",
      "2                         NaN        NaN        none   \n",
      "3                         NaN    Florida    democrat   \n",
      "4  Wisconsin Assembly speaker  Wisconsin  republican   \n",
      "\n",
      "                     context  \n",
      "0            a floor speech.  \n",
      "1                     Denver  \n",
      "2             a news release  \n",
      "3        an interview on CNN  \n",
      "4  a an online opinion-piece  \n",
      "Index(['label', 'statement', 'subject', 'speaker', 'speaker_job', 'state',\n",
      "       'party', 'context'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "D = pd.read_csv(\"train.tsv\", sep=\"\\t\", header = 0)\n",
    "print(D.head())\n",
    "print(D.columns)\n",
    "y = 1*(D.label == \"pants-fire\").values\n",
    "X = D.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"test_noy.tsv\", sep=\"\\t\", header = 0)\n",
    "X_test = d.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in c:\\users\\ja\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (41.0.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.16.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.45.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\ja\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (0.5.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in c:\\users\\ja\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.16.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (41.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.45.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2019.6.16)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\ja\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ja\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (0.5.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp2 = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"statement_spacy\"] = X.statement.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"statement_spacy\"] = X_test.statement.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lematyzacja\n",
    "def lemmatize(x):\n",
    "  l = []\n",
    "  for d in x:\n",
    "    l.append(\" \".join(t.lemma_ for t in d))\n",
    "  return l\n",
    "Lemmatizer = FunctionTransformer(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vec(X):\n",
    "    d1 = X.apply(nlp2, disable =[\"parser\", \"tagger\", \"ner\"])\n",
    "    return np.array([d.vector for d in d1])\n",
    "\n",
    "doc2vec_transf = FunctionTransformer(text_to_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(s):\n",
    "    s = s.astype('str')\n",
    "    n = s.str.len().values\n",
    "    n_w = s.str.split().str.len()\n",
    "    avg_w_len = n.astype(float)/n_w\n",
    "    return np.column_stack([n, n_w, avg_w_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(x):\n",
    "    l = []\n",
    "    for el in x:\n",
    "        l.append(\" \".join(ent.label_ for ent in el.ents))\n",
    "    return l\n",
    "NamedEntityRecognition= FunctionTransformer(ner)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(x):\n",
    "  l = []\n",
    "  for d in x:\n",
    "    l.append(\" \".join(t.pos_ for t in d))\n",
    "  return l\n",
    "PartOfSpeechTagging = FunctionTransformer(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posdet(x):\n",
    "  l = []\n",
    "  for d in x:\n",
    "    l.append(\" \".join(t.tag_ for t in d))\n",
    "  return l\n",
    "PartOfSpeechTaggingDetailed = FunctionTransformer(posdet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_length(x):\n",
    "  l = []\n",
    "  for d in x:\n",
    "    words = d.split()\n",
    "    average = sum(len(word) for word in words) / len(words)\n",
    "    l.append(average)\n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#średnia długość słowa w dokumencie\n",
    "X[\"average\"] = avg_length(X.statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"average\"] = avg_length(X_test.statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ilość słów w dokumencie\n",
    "def number_words(x):\n",
    "  l = []\n",
    "  for d in x:\n",
    "    len_words = len(d.split())\n",
    "    l.append(len_words)\n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"number\"] = number_words(X.statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"number\"] = number_words(X_test.statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([(\"statement\", make_pipeline(Lemmatizer,TfidfVectorizer(stop_words = \"english\")), \"statement_spacy\"),\n",
    "                        (\"statementPOS\", make_pipeline(PartOfSpeechTagging,TfidfVectorizer(stop_words = \"english\")), \"statement_spacy\"),\n",
    "                        (\"statementPOSDetailed\", make_pipeline(PartOfSpeechTaggingDetailed,TfidfVectorizer(stop_words = \"english\")), \"statement_spacy\"),\n",
    "                        (\"statementNER\", make_pipeline(NamedEntityRecognition,TfidfVectorizer(stop_words = \"english\")), \"statement_spacy\"),\n",
    "                        (\"statement2vec\", doc2vec_transf, \"statement\"),\n",
    "                        (\"statement_svd1\", Pipeline([(\"TFIDF\", TfidfVectorizer()), (\"svd\", TruncatedSVD(n_components = 1000, n_iter=10))]), \"statement\"),\n",
    "                        (\"statement_svd2\", Pipeline([(\"TFIDF\", TfidfVectorizer()), (\"svd\", TruncatedSVD(n_components = 500, n_iter=10))]), \"statement\"),\n",
    "                        (\"statement_svd3\", Pipeline([(\"TFIDF\", TfidfVectorizer()), (\"svd\", TruncatedSVD(n_components = 100, n_iter=10))]), \"statement\"),\n",
    "                        (\"funcTrans\", FunctionTransformer(func=extract_text_features, validate = False, accept_sparse = True), \"statement\"), \n",
    "                        (\"party\", TfidfVectorizer(), \"party\"),\n",
    "                        (\"context\", TfidfVectorizer(ngram_range =(1,2)), \"context\"),\n",
    "                        (\"speaker_job\", HashingVectorizer(), \"speaker_job\"),\n",
    "                        (\"speaker\", TfidfVectorizer(ngram_range =(1,2)), \"speaker\"), \n",
    "                        (\"subject\", TfidfVectorizer(), \"subject\"),\n",
    "                        (\"avg_length\", \"passthrough\" , [\"average\"]),\n",
    "                        (\"number_words\", \"passthrough\" , [\"number\"])\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model wybrany za pomocą GridSearchCV\n",
    "model = LogisticRegression(solver='newton-cg', penalty= \"l2\", C = 0.5, n_jobs=-1)\n",
    "p= Pipeline([(\"ct\", ct),(\"l\",model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Jakość dopasowania modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(p,X,y,scoring=\"roc_auc\")\n",
    "score.mean()\n",
    "#wynik na zbiorze treningowym\n",
    "#0.7634088419984134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dopasowanie modelu\n",
    "p.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scory na zbiorze testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = p.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.62755098, -2.02704756, -1.46937001, ..., -1.19378622,\n",
       "       -2.16793641, -3.44960607])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = p.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "probab_test = y_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02660189, 0.12873048, 0.16606767, ..., 0.19926521, 0.09286273,\n",
       "       0.04526488])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('score_testowy_textmining', 'w') as f:\n",
    "    for item in lst:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
